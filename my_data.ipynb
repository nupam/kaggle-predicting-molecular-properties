{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp.nb_01 import *\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import fastai\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def get_data():\n",
    "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n",
    "\n",
    "def normalize(x, m, s): return (x-m)/s\n",
    "\n",
    "def stat(x): return x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10), 64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()\n",
    "n,m = x_train.shape\n",
    "c = y_train.max()+1\n",
    "nh = 64\n",
    "n,m,c, nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-7.6999e-06), tensor(1.), tensor(-0.0059), tensor(0.9924))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##normalize\n",
    "mean, std = x_train.mean(), x_train.std()\n",
    "x_train = normalize(x_train, mean, std)\n",
    "x_valid = normalize(x_valid, mean, std)\n",
    "x_train.mean(), x_train.std(), x_valid.mean(), x_valid.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, ni, nh, no):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(ni, nh)\n",
    "        self.l2 = nn.Linear(nh, no)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        return self.l2(F.relu(self.l1(inp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (l1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (l2): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(m, nh, int(c))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(pred, targ):\n",
    "    return (pred.argmax(dim=1) == targ).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, x, y):\n",
    "        assert len(x) == len(y)\n",
    "        self.x, self.y = x, y\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, slice):\n",
    "            return Dataset(self.x[idx], self.y[idx])\n",
    "        else:\n",
    "            return self.x[idx], self.y[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
    "assert len(train_ds)==len(x_train)\n",
    "assert len(valid_ds)==len(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "    def __init__(self, ds, bs=64, shuffle=True):\n",
    "        print('sampler init, n: ', len(ds) )\n",
    "        self.n, self.bs, self.shuffle = len(ds), bs, shuffle\n",
    "        self.idxs = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for i in range(0, self.n, self.bs):\n",
    "            yield self.idxs[i : min(self.n, i+self.bs)]\n",
    "            \n",
    "\n",
    "def collate(batch):\n",
    "    x, y = zip(*batch)\n",
    "    x, y = torch.stack(x), torch.stack(y)\n",
    "    return x, y\n",
    "\n",
    "class Dataloader:\n",
    "    def __init__(self, ds, bs=64, shuffle=True, collate_fn=collate):\n",
    "        print('init called')\n",
    "        self.ds, self.bs, self.shuffle, self.collate_fn = ds, bs, shuffle, collate_fn\n",
    "        self.sampler = Sampler(self.ds, self.bs, self.shuffle)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for idxs in self.sampler:\n",
    "            #print('indexes', idxs)\n",
    "            yield self.collate_fn([self.ds[i] for i in idxs])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return (len(self.ds)-1)//self.bs + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init called\n",
      "sampler init, n:  10\n"
     ]
    }
   ],
   "source": [
    "train_dl = Dataloader(train_ds[:10], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = next(it)\n",
    "for i in range(len(x)):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(x[i].view(28,28), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(str(y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdls(train_ds, test_ds, bs):\n",
    "    return Dataloader(train_ds, bs), Dataloader(test_ds, 2*bs, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class optimizer:\n",
    "    def __init__(self, params, lr=0.01):\n",
    "        self.params, self.lr = list(params), lr\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params:\n",
    "                p -= p.grad*self.lr\n",
    "                \n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad.data.zero_()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, epochs, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        for x, y in train_dl:\n",
    "            preds = model(x)\n",
    "            loss = loss_func(preds, y)\n",
    "            loss.backward()\n",
    "            \n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tot_loss,tot_acc = 0.,0.\n",
    "            for xb,yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                tot_loss += loss_func(pred, yb)\n",
    "                tot_acc  += acc(pred,yb)\n",
    "        nv = len(valid_dl)\n",
    "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
    "    return tot_loss/nv, tot_acc/nv\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init called\n",
      "sampler init, n:  50000\n",
      "init called\n",
      "sampler init, n:  10000\n",
      "0 tensor(0.1501) tensor(0.9587)\n",
      "1 tensor(0.1178) tensor(0.9661)\n",
      "2 tensor(0.1045) tensor(0.9684)\n",
      "3 tensor(0.0976) tensor(0.9702)\n",
      "4 tensor(0.0931) tensor(0.9729)\n",
      "5 tensor(0.0915) tensor(0.9738)\n",
      "6 tensor(0.0897) tensor(0.9743)\n",
      "7 tensor(0.0894) tensor(0.9745)\n",
      "8 tensor(0.0910) tensor(0.9746)\n",
      "9 tensor(0.0921) tensor(0.9744)\n",
      "10 tensor(0.0961) tensor(0.9736)\n",
      "11 tensor(0.0985) tensor(0.9738)\n",
      "12 tensor(0.1012) tensor(0.9736)\n",
      "13 tensor(0.1031) tensor(0.9735)\n",
      "14 tensor(0.1045) tensor(0.9736)\n",
      "15 tensor(0.1052) tensor(0.9742)\n",
      "16 tensor(0.1055) tensor(0.9745)\n",
      "17 tensor(0.1060) tensor(0.9753)\n",
      "18 tensor(0.1064) tensor(0.9750)\n",
      "19 tensor(0.1071) tensor(0.9752)\n",
      "CPU times: user 2min 33s, sys: 391 ms, total: 2min 34s\n",
      "Wall time: 23.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.1071), tensor(0.9752))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(m, nh, 10)\n",
    "%time fit(model, 20, F.cross_entropy, optimizer(model.parameters(), 0.1), *getdls(train_ds, valid_ds, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".torch",
   "language": "python",
   "name": ".torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
